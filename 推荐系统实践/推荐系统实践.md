## 1. 推荐系统

1. 推荐系统简介
2. 与搜索引擎的区别
3. 推荐系统评测

### 1.1 推荐系统简介
随着互联网发展，信息匮乏走向信息过载（information overload）

两个挑战：
1. 信息消费者，如何找到感兴趣的信息
2. 信息生产者，如何使生产的信息脱颖而出

推荐系统是解决两个问题的重要工具。推荐系统的任务是**联系用户和信息**。
1. 帮助用户找到有价值的信息
2. 信息展现在对它感兴趣的用户面前

### 1.2 与搜索引擎的区别
面对信息过载，代表性的解决方案是分类目录和搜索引擎（雅虎、谷歌）。

##### 从用户角度出发：

搜索引擎需要**用户主动提供准确的关键词**。

推荐系统**不需要用户提供显示需求**，而是分析用户的历史行为，主动给用户推荐满足兴趣和需求的信息。

一定程度上，推荐和搜索是两个互补的工具。
- 搜索引擎满足用户**有明确目的**的主动查找需求。
- 推荐系统在用户**没有明确目的**时帮助他们发现感兴趣的内容。

##### 从物品角度出发：

推荐系统可以更好的**发掘长尾**（long tail）。

推荐系统通过挖掘用户行为，从长尾商品中准确的推荐给用户，提高长尾销售额。

### 1.3 推荐系统评测

推荐系统组成：用户、物品提供者和推荐系统网站。

##### 推荐系统实验方法：
1. **离线实验**：只利用日志系统数据训练测试。
2. **用户调查**：通过用户问卷行为和答案了解系统的性能。
3. **在线实验**：线上AB测试。如下图所示:

![image](https://raw.githubusercontent.com/xvlvzhu/reading-notes/master/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5/figure/1.ABtest.png)

##### 评测指标：
1. **用户满意度**
2. **预测准确度**

```math
\operatorname { RMSE } = \frac { \sqrt { \sum _ { u , k \in T } \left( r _ { u i } - \hat { r } _ { u i } \right) ^ { 2 } } } { | T | }
```


```math
\mathrm { MAE } = \frac { \sum _ { u , i \in T } \left| r _ { u i } - \hat { r } _ { u i } \right| } { | T | }
```

`$u$`：用户，`$i$`：物品，`$r_{ui}$`：用户u对物品i的实际评分，`$\hat{r}_{ui}$`:推荐算法给出的预测评分

```math
\operatorname { Recall } = \frac { \sum _ { u \in U } | R ( u ) \cap T ( u ) | } { \sum _ { u \in U } | T ( u ) | }
```


```math
\operatorname { Precision }= \frac { \sum _ { u \in U } | R ( u ) \cap T ( u ) | } { \sum _ { i \in U } | R ( u ) | }
```

`$R(u)$`：根据用户在训练集上的行为给用户作出的推荐列表

`$T(u)$`：是用户在测试集上的行为列表

3. **覆盖率**：描述推荐系统对物品长尾的发掘能力。

```math
\operatorname { Coverage }= \frac { \left| \bigcup _ { u \in \mathrm { U } } R ( u ) \right| } { | I | }
```
系统的用户集合为`$U$`，推荐系统给每个用户推荐一个长度为N的物品列表`$R(u)$`。

4. **多样性**：推荐列表中物品两两之间的不相似性。

```math
\operatorname { Diversity }= 1 - \frac { \sum _ { i , j \in R ( u ) , i \neq j } s ( i , j ) } { \frac { 1 } { 2 } | R ( u ) | ( | R ( u ) | - 1 ) }
```

`$s(i, j)$`：物品`$i$`和`$j$`之间的相似度；

整个系统的推荐多样性：

```math
\operatorname { Diversity }= \frac { 1 } { | U | _ { u \in U } } \operatorname { Diversity } ( R ( u ) )
```

5. **新颖性**：一般热度越低，新颖性越高
6. **惊喜度**：推荐结果和用户历史兴趣不相似，但却让用户满意，惊喜度就较高
7. **信任度**：用户对推荐系统的信任。需要增加推荐透明度（提供推荐解释）。社交好友的推荐（评论信任）。
8. **实时性**：用户行为后推荐的及时性，新物品的冷启动能力。 
9. **健壮性**：推荐系统抗击作弊的能力。提高健壮性的方式：1.尽量使用代价比较高的用户行为（如购买行为）。2.进行数据清理。
10. **商业目标**
11. **总结**：优化离线指标，在给定覆盖率，多样性、新颖性等限制条件下，尽量优化预测准确度。离线实验的优化目标是：

```
max 预测准确率
st. 覆盖率>A
    多样性>B
    新颖性>C
```
---

## 2. 利用用户行为数据

用户行为数据蕴含着很多不是那么显而易见的规律（如啤酒和尿布），个性化推荐算法的任务是通过计算机发现这些规律，为产品的设计提供指导。

### 2.1 用户行为数据
用户行为数据的一般存在形式是**日志**。

- 展示日志：用户查询后页面中展示的结果
- 点击日志：用户的点击行为
- 会话日志：展示日志和点击日志的归并

会话日志通常存储于分布式数据仓库中。
- 支持离线分析的**Hadoop Hive**
- 支持在线分析的**Google Dremel**

用户行为分为两种：
- 显示反馈行为（explicit feedback）：用户明确表示对物品喜好的行为（如评分）。
- 隐式反馈行为（implicit feedback）：不能明确反应用户喜好的行为（如页面浏览）。

用户行为可以统一表示为下表：

字段 | 意义
---|---
user id| 产生行为的用户的唯一标识
item id| 产生行为的对象的唯一标识
behavior type| 行为的种类（比如是购买还是浏览）
context| 产生行为的上下文，包括时间和地点等
behavior weight| 行为的权重（如浏览时长）
behavior content| 行为的内容（如评论文本）

考虑到隐式/显示，有无上下文，数据可以分为以下几类：


用户反馈| 上下文信息| 包含内容|示例
---|---|---|---
隐性 | 无 | 用户ID和物品ID| [Book-Crossing](http://www.informatik.uni-freiburg.de/~cziegler/BX/)
显性 | 无 | 用户ID、物品ID，用户对物品评分|
隐性 | 有 | 用户ID、物品ID和行为时间戳|[Last.fm](http://www.dtic.upf.edu/~ocelma/MusicRecommendationDataset/lastfm-1K.html)
显性 | 无 | 用户ID、物品ID，用户对物品评分、行为时间戳|[Netflix.Price](https://netflixprize.com/)

### 2.2 用户行为分析

- 物品流行度和用户活跃度一般呈长尾分布。
- 用户越活跃，更倾向浏览冷门物品。

基于用户行为数据设计的推荐算法一般称为**协同过滤算法**。主流方法有一下几种：

- 基于近邻的方法（neighborhood-based）
    - 基于用户的协同过滤算法：给用户推荐与他兴趣相似的其他用户喜欢的物品
    - 基于物品的协同过滤算法：给用户推荐与他之前喜欢的物品相似的物品
- 隐语义模型（latent factor model）
- 基于图的随机游走算法（random walk on graph）

### 2.3 基于邻域的算法

#### 2.3.1 基于用户的协同过滤算法
1. 找到和目标用户兴趣相似的用户集合
2. 找到这个集合中的用户喜欢的，且目标用户没有行为记录的物品推荐给目标用户

给定用户`$u$`和用户`$v$`，`$N(u)$`表示用户`$u$`曾经有过正反馈的物品集合，`$N(v)$`为用户`$v$`曾经有过正反馈的物品集合。利用Jaccard公式计算兴趣相似度：

```math
w _ { u v } = \frac { | N ( u ) \cap N ( v ) | } { | N ( u ) \cup N ( v ) | }
```
或通过余弦相似度计算：

```math
w _ { u v } = \frac { | N ( u ) \cap N ( v ) | } { \sqrt { | N ( u ) | | N ( v ) | } }
```

用户相似度计算改进（User-IIF算法）：

对于热度较大的物品`$i$`进行权重惩罚，热度越大的商品在相似度计算中占得的权重越低：
```math
w _ { u v } = \frac { \sum _ { i \in N ( u ) \cap N ( v ) } \frac { 1 } { \log 1 + | N ( i ) | } } { \sqrt { | N ( u ) | | N ( v ) | } }
```
##### UserCF代码：

```python
# 计算用户相似度矩阵
def UserSimilarity(train, mode='UserCF'):
    # build inverse table for item_users
    item_users = dict()
    for u, items in train.items():
        for i in items.keys():
            if i not in item_users:
                item_users[i] = set()
            item_users[i].add(u)
            
    #calculate co-rated items between users
    C = dict()
    N = dict()
    for i, users in item_users.items():
        for u in users:
            N[u] += 1
            for v in users:
                if u == v:
                    continue
                if mode=='UserCF':
                    C[u][v] += 1 # UserCF算法
                else:
                    C[u][v] += 1 / math.log(1 + len(users)) # User-IIF算法
                
    #calculate finial similarity matrix W
    W = dict()
    for u, related_users in C.items():
        for v, cuv in related_users.items():
            W[u][v] = cuv / math.sqrt(N[u] * N[v])
    return W

# 根据用户相似度矩阵进行推荐
def Recommend(user, train, W):
    rank = dict()
    interacted_items = train[user]
    for v, wuv in sorted(W[u].items, key=itemgetter(1), \
        reverse=True)[0:K]:
        for i, rvi in train[v].items:
            if i in interacted_items:
                #we should filter items user interacted before
                continue
            rank[i] += wuv * rvi
    return rank
```

#### 2.3.2 基于物品的协同过滤算法
1. 计算物品之间的相似度。
2. 根据物品的相似度和用户的历史行为给用户生成推荐列表。

物品相似度计算公式：

```math
w _ { i j } = \frac { | N ( i ) \cap N ( j ) | } { \sqrt { | N ( i ) || N ( j ) | } }
```

`$|N(i)|$`是喜欢物品`$i$`的用户数，`$|N(j)|$`是喜欢物品`$j$`的用户数，`$|N(i) \cap N(j)|$`是同时喜欢物品`$i$`和物品`$j$`的用户数.

物品相似度的修正公式IUF（Inverse User Frequence）：活跃用户对物品的相似度的贡献应小于不活跃的用户。

```math
w _ { i j } = \frac { \sum _ { u \in N ( i ) N ( j ) } \frac { 1 } { \log 1 + | N ( u ) | } } { \sqrt { | N ( i ) | | N ( j ) | } }
```

`$|N(u)|$`为用户`$u$`喜欢物品的数量。


```python
# 计算物品相似度矩阵
def ItemSimilarity(train, mode='ItemCF'):
    #calculate co-rated users between items
    C = dict()
    N = dict()
    for u, items in train.items():
        for i in users:
            N[i] += 1
            for j in users:
                if i == j:
                    continue
                if mode=='ItemCF':
                    C[i][j] += 1 # ItemCF算法
                else:
                    C[i][j] += 1 / math.log(1 + len(items) * 1.0) # ItemCF-IUF
            
    #calculate finial similarity matrix W
    W = dict()
    for i,related_items in C.items():
        for j, cij in related_items.items():
            W[u][v] = cij / math.sqrt(N[i] * N[j])
    return W
    
def Recommendation(train, user_id, W, K):
    rank = dict()
    ru = train[user_id]
    for i,pi in ru.items():
        for j, wj in sorted(W[i].items(), \
                            key=itemgetter(1), reverse=True)[0:K]:
            if j in ru:
                continue
            rank[j].weight += pi * wj # 计算用户对物品j的兴趣度
            rank[j].reason[i] = pi * wj
    return rank
```

物品相似度归一化：ItemCF相似度矩阵按最大值归一化，可以提高推荐的准确率。
```math
w _ { i j } ^ { \prime } = \frac { w _ { i j } } { \mathop {\max }\limits_j w _ { i j } }

```

#### 2.3.3 UserCF和ItemCF对比



-|UserCF | ItemCF
---|---|---
性能|适用于用户较少的场合，如果用户很多，计算用户相似度矩阵代价很大 | 适用于物品数明显小于用户数的场合，如果物品很多（网页），计算物品相似度矩阵代价很大
领域| 时效性较强，用户个性化兴趣不太明显的领域 | 长尾物品丰富，用户个性化需求强烈的领域
实时性|用户有新行为，不一定造成推荐结果的立即变化|用户有新行为，一定会导致推荐结果的实时变化
冷启动| 在新用户对很少的物品产生行为后，不能立即对他进行个性化推荐，因为用户相似度表是每隔一段时间离线计算的。新物品上线后一段时间，一旦有用户对物品产生行为，就可以将新物品推荐给和对它产生行为的用户兴趣相似的其他用户| 新用户只要对一个物品产生行为，就可以给他推荐和该物品相关的其他物品。但没有办法在不离线更新物品相似度表的情况下将新物品推荐给用户
推荐理由| 很难提供令用户信服的推荐解释|利用用户的历史行为给用户做推荐解释，可以令用户比较信服

### 2.4 隐语义模型

隐语义模型（latent factor model）通过**隐含特征**（latent factor）联系用户的兴趣和物品。

隐语义模型包括pLSA、LDA、隐含类别模型、隐含主题模型、矩阵分解（matrix factorization）。

#### 2.4.1 LFM模型

LFM通过如下公式计算用户u对物品i的兴趣：


```math
\operatorname { Preference }( u , i ) = r _ { u i } = p _ { u } ^ { T } q _ { i } = \sum _ { f = 1 } ^ { F } p _ { u , k } q _ { i , k }
```

`$p _ { u , k }$`和`$q _ { i , k }$`是模型的参数，其中`$p _ { u , k }$`度量了用户`$u$`的兴趣和第`$k$`个隐类的关系，而`$q _ { i , k }$`度量了第`$k$`个隐类和物品`$i$`之间的关系。

计算`$p _ { u , k }$`和`$q _ { i , k }$`需要一个训练集，包括用户`$u$`喜欢的物品和不感兴趣的物品。但是在隐式反馈数据集中没有负样本（用户不感兴趣的物品）。

LFM的应用需要解决**负样本生成**问题。一种基本方法是：对于一个用户，从他没有过行为的物品中采样出一些物品作为负样本，采样时，保证每个用户的正负样本数目相当。


实验表明负样本采样应包含以下原则：
- 对每个用户，要保证正负样本的平衡（数目相似）。
- 对每个用户采样负样本时，要选取那些很热门，而用户却没有行为的物品。


```python
# 负样本采样过程
def RandomSelectNegativeSample(self, items):
    ret = dict()
    for i in items.keys():
        ret[i] = 1
    n = 0
    for i in range(0, len(items) * 3):
        item = items_pool[random.randint(0, len(items_pool) - 1)] # items_pool候选物品列表
        if item in ret:
            continue
        ret[item] = 0
        n + = 1
        if n > len(items):
            break
    return ret
```

经过负采样得到用户-物品样本`$K={(u,i)}$`，其中如果`$(u, i)$`是正样本，则有`$r_{ui}=1$`，否则`$r_{ui}=0$`。

然后优化一下损失寻找合适的`$p$`和`$q$`：
```math
C = \sum _ { ( u , i ) \in K } \left( r _ { u i } - \hat { r } _ { u i } \right) ^ { 2 } = \sum _ { ( u , i ) \in K } \left( r _ { u i } - \sum _ { k = 1 } ^ { K } p _ { u , k } q _ { i , k } \right) ^ { 2 } + \lambda \left\| p _ { u } \right\| ^ { 2 } + \lambda \left\| q _ { i } \right\| ^ { 2 }
```

`$\lambda \left\| p _ { u } \right\| ^ { 2 } + \lambda \left\| q _ { i } \right\| ^ { 2 }$`为防止过拟合的正则项，`$\lambda$`为超参数，通过随机梯度下降算法，优化参数。

对参数`$p$`和`$q$`**求偏导数**:


```math
\begin{array} { l } { \frac { \partial C } { \partial p _ { u k } } = - 2 q _ { i k } + 2 \lambda p _ { u k } } \\ \\ { \frac { \partial C } { \partial q _ { k k } } = - 2 p _ { u k } + 2 \lambda q _ { l k } } \end{array}
```

梯度下降法更新参数：

```math
\begin{aligned} p _ { u k } & = p _ { u k } + \alpha \left( q _ { i k } - \lambda p _ { u k } \right) \\ q _ { i k } & = q _ { i k } + \alpha \left( p _ { u k } - \lambda q _ { i k } \right) \end{aligned}
```


```python
# LMF 模型训练
def LatentFactorModel(user_items, F, N, alpha, lambda):
    [P, Q] = InitModel(user_items, F)
    for step in range(0,N):
        for user, items in user_items.items():
            samples = RandSelectNegativeSamples(items) # 采样负样本
            for item, rui in samples.items():
                eui = rui - Predict(user, item) # 计算误差
                for f in range(0, F):
                    P[user][f] += alpha * (eui * Q[item][f] - \
                        lambda * P[user][f]) # 更新用户矩阵
                    Q[item][f] += alpha * (eui * P[user][f] - \
                        lambda * Q[item][f]) # 更新物品矩阵
        alpha *= 0.9

def Recommend(user, P, Q):
    rank = dict()
    for f, puf in P[user].items():
        for i, qfi in Q[f].items():
            if i not in rank:
                rank[i] += puf * qfi
    return rank
```

#### 2.4.2 LMF与基于邻域的方法对比


-|LMF | 基于邻域
---|---|---
理论|最优化方法 | 统计方法
空间复杂度|`$O(F\times (M+ N))$` | `$O(M\times M)$`或`$O(N\times N)$`
时间复杂度|`$O(K\times F\times S)$`|`$O(N\times (K/N)^2)$`或`$O(M\times (K/M)^2)$`
在线实时推荐| 不能 |可以
推荐解释|不能|ItemCF可以

`$M$`个用户，`$N$`个物品，`$K$`条用户对物品的行为记录

### 2.5 基于图的模型

将用户行为数据表示为**图**的形式。

用户行为数据是由二元组组成，每个二元组(u, i)表示用户u对物品i产生过行为。

![image](https://github.com/xvlvzhu/reading-notes/blob/master/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5/figure/2.graph_model.png?raw=true)

`$G(V,E)$`表示用户物品二分图，`$V = V _ { U } \cup V _ { I }$` 表示用户和物品的顶点集合，边`$e \left( v _ { u } , v _ { i } \right)$`表示用户u对物品i产生过行为。

给用户u推荐物品的任务转化为：度量`$v_u$`和与`$v_u$`没有直接相连的物品节点的相关性。

#### 2.5.1 随机游走算法

从用户`$u$`对应的节点`$v_u$`开始在用户物品二分图上进行随机游走。游走到任何一个节点时，首先按照概率`$\alpha$`决定是继续游走，还是停止这次游走并从`$v_u$`节点开始重新游走。如果决定继续游走，那么就从当前节点指向的节点中按照均匀分布随机选择一个节点作为游走下次经过的节点。经过很多次随机游走后，每个物品节点被访问到的概率会收敛到一个数。最终的推荐列表中物品的权重就是物品节点的访问概率。

```math
{\rm{PR}}(v)\left\{ \begin{array}{l}
\alpha \sum\limits_{{v^\prime } \in {\rm{in}}(v)} {\frac{{{\rm{PR}}\left( {{v^\prime }} \right)}}{{\left| { out \left( {{v^\prime }} \right)} \right|}}} \quad \left( {v \ne {v_u}} \right)\\
(1 - {\rm{ }}\alpha ) + \alpha \sum\limits_{{v^\prime } \in  in (v)} {\frac{{ PR \left( {{v^\prime }} \right)}}{{\left| { out \left( {{v^\prime }} \right)} \right|}}} \quad \left( {v = {v_u}} \right)
\end{array} \right.
```

---

## 3. 推荐系统冷启动问题

### 3.1 冷启动问题简介
在没有大量用户数据的情况下设计推荐系统，即为冷启动问题。

冷启动问题（cold start）分为三类。
- 用户冷启动：新用户的推荐问题
- 物品冷启动：把新物品推荐给感兴趣的用户
- 系统冷启动：在新开发的网站上设计个性化推荐系统

一般来说有如下解决方案：
1. 提供非个性化的推荐，例如排行榜。
2. 利用用户注册时提供的年龄、性别等数据做粗粒度的个性化。
3. 利用用户的社交网络账号登录（需要用户授权），导入用户在社交网站上的好友信息，然后给用户推荐其好友喜欢的物品。
4. 要求用户在登录时对一些物品进行反馈，收集用户对这些物品的兴趣信息，然后给用户
推荐那些和这些物品相似的物品。
5. 对于新加入的物品，可以利用内容信息，将它们推荐给喜欢过和它们相似的物品的用户。
6. 在系统冷启动时，可以引入专家的知识，通过一定的高效方式迅速建立起物品的相关度表。

### 3.2 利用用户注册信息推荐

用户注册信息分三类：

1. 人口统计学信息：包括用户的年龄、性别、职业、民族、学历和居住地。
2. 户兴趣的描述：有一些网站会让用户用文字描述他们的兴趣。
3. 从其他网站导入的用户站外行为数据：比如用户通过豆瓣、新浪微博的账号登录，就可以在得到用户同意的情况下获取用户在豆瓣或者新浪微博的一些行为数据和社交网络数据。

基于注册信息的个性化推荐流程基本如下：
1. 获取用户的注册信息；
2. 根据用户的注册信息对用户分类；
3. 给用户推荐他所属分类中用户喜欢的物品。

![image](https://github.com/xvlvzhu/reading-notes/blob/master/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5/figure/3.cold_start.png?raw=true)

基于用户注册信息的推荐算法：计算每种特征的用户喜欢的物品。
```math
p ( f , i ) = | N ( i ) \cap U ( f ) |
```
`$p ( f , i ) $`定义为物品`$i$`在具有`$f$`特征的用户中的热门度。`$ N ( i )$`是喜欢物品`$i$`的用户集合，`$U(f)$` 是具有特征`$f$`的用户集合。


往往热门的物品在各类用户特征中都具有较高的权重，所以对热门物品的热门程度做以下修正：

```math
p ( f , i ) = \frac { | N ( i ) \cap U ( f ) | } { | N ( i ) | + \alpha }
```

参数`$\alpha$`用于解决数据稀疏问题。

### 3.3 选择合适的物品启动用户兴趣

用户第一次访问系统时，给用户提供一些物品，让用户去反馈对这些商品的兴趣。

![image](https://github.com/xvlvzhu/reading-notes/blob/master/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5/figure/4.cold_start_rating.png?raw=true)

#### 3.3.1 候选物品选择

用来启动用户兴趣的物品需要具有以下特点：

- 比较热门
- 具有代表性和区分性
- 启动物品集合需要有多样性

### 3.4 利用物品的信息内容

物品的内容信息多种多样，不同类型的物品有不同的内容信息。一般来说，物品的内容可以通过向量空间模型表示。

对物品d，它的内容表示成一个关键词向量如下：
```math
d _ { i } = \left\{ \left( e _ { 1 } , w _ { 1 } \right) , \left( e _ { 2 } , w _ { 2 } \right) , \cdots \right\}
```
`$ e _ { i } $`就是关键词，`$w _ { i }$`是关键词对应的权重

在给定物品内容的关键词向量后，物品的内容相似度可以通过向量之间的余弦相似度计算：

```math
w _ { i j } = \frac { d _ { i } \cdot d _ { j } } { \sqrt { \left\| d _ { i } \right\| \left\| d _ { j } \right\| } }
```

得到物品的相似度之后，就可以给用户推荐和他历史上喜欢的物品内容相似的物品。

> **实验结论**：如果用户的行为强烈受某一内容属性的影响，那么内容过滤的算法还是可以在精度上超过协同过滤算法的。

#### 3.4.1 话题模型

有些物品的信息由分子描述，话题模型主要研究**文章、话题和关键词的关系**。

经典的话题模型**LDA**，是一种生成模型，对一篇文档产生的过程进行了建模。一个人在写一篇文档的时候，会首先想这篇文章要讨论哪些话题，然后思考这些话题应该用什么词描述，从而最终用词写成一篇文章。因此，文章和词之间是通过话题联系的。

- [ ] ==LDA算法原理==

---

## 4. 利用用户标签数据

除了基于UserCF、ItemCF方法，还有一种方法是通过一些特征（feature）联系用户和物品。一种重要的特征表示方法是**标签**。

![image](https://github.com/xvlvzhu/reading-notes/blob/master/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5/figure/5.using_tags.png?raw=true)

**标签**是一种无层次化结构的、用来描述信息的关键词，它可以用来描述物品的语义。

**标签应用**一般分两种：
1. 作者或者专家给物品打标签
2. 普通用户给物品打标签，也称UGC（User Generated Content）

### 4.1 设计标签

普通用户对物品打标签时，需要有一套完整的标签集，主要包括：

1. 表明物品是什么
2. 表明物品的种类
3. 表明谁拥有物品
4. 表达用户的观点
5. 用户相关的标签
6. 用户的任务
7. 类型（Genre）
7. 时间（Time）
8. 人物（People）
9. 地点（Place）
10. 语言（Language）
11. 奖项（Awards）
12. 其他（Details）

### 4.2 基于标签的推荐系统

基于标签的推荐系统的算法过程如下：

1. 统计每个用户最常用的标签。
2. 对于每个标签，统计被打过这个标签次数最多的物品。
3. 对于一个用户，首先找到他常用的标签，然后找到具有这些标签的最热门物品推荐给这个用户。

##### SimpleTagBased

对于上面的算法，用户`$u$`对物品`$i$`的兴趣公式如下：

```math
p ( u , i ) = \sum _ { b } n _ { u , b } n _ { b , i }
```
`$B(u)$`是用户`$u$`打过的标签集合，`$B(i)$`是物品`$i$`被打过的标签集合，`$n_{u,b}$`是用户u打过标签`$b$`的次数，`$n_{b,i}$`是物品`$i$`被打过标签`$b$`的次数。

##### TagBasedTFIDF

上面的公式倾向于给热门标签对应的热门物品很大的权重，导致推荐结果缺乏新颖性。借鉴TD-IDF思想对公式进行改进，降低热门标签的权重：


```math
p ( u , i ) = \sum _ { b } \frac { n _ { u , b } } { \log \left( 1 + n _ { b } ^ { ( u ) } \right) } n _ { b , i }
```
`$n _ { b } ^ { ( u ) }$` 记录了标签`$b$`被多少个不同的用户使用过。

##### TagBasedTFIDF++

同理，还可以借鉴TF-IDF的思想对热门物品进行惩罚：


```math
p ( u , i ) = \sum _ { b } \frac { n _ { u , b } } { \log \left( 1 + n _ { b } ^ { ( u ) } \right) } \frac { n _ { b , i } } { \log \left( 1 + n _ { i } ^ { ( u ) } \right) }
```
`$n _ { i } ^ { ( u ) }$` 记录了物品i被多少个不同的用户打过标签。

#### 4.2.1 数据稀疏性

对于新用户或者新物品，集合`$B(u) \cap B(i)$`中的标签数量会很少。可通过相似标签对标签集进行扩展。以下公式度量了标签`$b$`和标签`$b'$`之间的相似度。

```math
\operatorname { sim } \left( b , b ^ { \prime } \right) = \frac { \sum _ { i \in N ( b ) \cap N \left( b ^ { \prime } \right) } n _ { b , i } n _ { b ^ { \prime } , i } } { \sqrt { \sum _ { i \in N ( b ) } n _ { b , i } ^ { 2 } \sum _ { i \in N \left( b ^ { \prime } \right) } n _ { b ^ { \prime } , i } ^ { 2 } } }
```
`$N(b)$`为有标签`$b$`的物品的集合，`$n_{b,i}$`为给物品`$i$`打上标签`$b$`的用户数。

#### 4.2.2 标签清理

1. 去除词频很高的停止词；
2. 去除因词根不同造成的同义词
3. 去除因分隔符造成的同义词

#### 4.2.3 基于图的推荐算法

`$(u,i,b)$`：用户`$u$`给物品`$i$`打了标签`$b$`的用户标签行为。

每一条行为在图中添加`$(u,i)$`，`$(u,b)$`，`$(i,b)$`三条边。如下图包含3个用户（A、B、C）、3个物品（a、b、c）和3个标签（1、2、3）。

![image](https://github.com/xvlvzhu/reading-notes/blob/master/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5/figure/6.graph_tags.png?raw=true)

在定义出用户—物品—标签图后，可以用++2.5节++中提到的随机游走算法计算所有物品节点相对于当前用户节点在图上的相关性，然后按照相关性从大到小的排序，给用户推荐排名最高的N个物品。

#### 4.2.4 推荐系统解释

基于标签的推荐的优势是可以利用标签做**推荐解释**。

- 用户对标签的兴趣对帮助用户理解为什么给他推荐某个物品更有帮助；
- 用户对标签的兴趣和物品标签相关度对于帮助用户判定自己是否喜欢被推荐物品具有同样的作用；
- 物品标签相关度对于帮助用户判定被推荐物品是否符合他当前的兴趣更有帮助；
- 客观事实类标签相比主观感受类标签对用户更有作用。

### 4.3 给用户推荐标签

当用户浏览某个物品时，标签系统希望用户能够给这个物品打上高质量的标签。

#### 4.3.1 如何给用户推荐标签

1. PopularTags：给用户u推荐整个系统里最热门的标签。
2. ItemPopularTags：给用户u推荐物品i上最热门的标签。
3. UserPopularTags： 给用户u推荐他自己经常使用的标签。
4. HybridPopularTags：2和3两种的融合。

---

## 5. 利用上下文信息

用户所处的**上下文**（context）包括用户访问推荐系统的**时间**、**地点**等对于提高推荐系统的效果是非常重要的。

### 5.1 时间上下文信息

上下文信息中最重要的时间上下文信息。

#### 5.1.1 时间效应简介

1. 用户兴趣是变化的
2. 物品是有生命周期的
3. 季节效应

#### 5.1.2 推荐系统的实时性

- 要求在每个用户访问推荐系统时，都根据用户这个**时间点前的行为**实时计算推荐列表。
- 推荐算法需要平衡考虑用户的**近期行为和长期行为**，即要让推荐列表反应出用户近期行为所体现的兴趣变化，又不能让推荐列表完全受用户近期行为的影响，要保证推荐列表对用户兴趣预测的延续性。

#### 5.1.3 推荐算法的时间多样性
推荐系统的时间**多样性**：推荐系统每天推荐结果的变化程度。

提高推荐结果的时间多样性分两步解决：

1. 保证推荐系统能够在用户有了新的行为后及时调整推荐结果，使推荐结果满足用户最近的兴趣。
2. 保证推荐系统在用户没有新的行为时也能够经常变化一下结果，具有一定的时间多样性。

如果用户没有行为，通过以下思路提高时间多样性：
- 在生成推荐结果时加入一定的随机性。比如从推荐列表前20个结果中随机挑选10个结果展示给用户，或者按照推荐物品的权重采样10个结果展示给用户。
- 记录用户每天看到的推荐结果，然后在每天给用户进行推荐时，对他前几天看到过很多次的推荐结果进行适当地降权。
- 每天给用户使用不同的推荐算法。可以设计很多推荐算法，比如协同过滤算法、内容过滤算法等，然后在每天用户访问推荐系统时随机挑选一种算法给他进行推荐。

#### 5.1.3 时间上下文推荐算法

##### 最近最热门算法

选择近期最热门的物品进行推荐。给定时间`$T$`，物品`$i$`最近的流行度`$n_{i}(T)$`可以定义为：

```math
n _ { i } ( T ) = \sum _ { ( u , i , t ) \in \operatorname { Train } , t < T } \frac { 1 } { 1 + \alpha ( T - t ) }
```

##### 时间上下文相关的ItemCF算法

原始的ItemCF算法：

- 利用用户行为离线计算物品之间的相似度；
- 根据用户的历史行为和物品相似度矩阵，给用户做在线个性化推荐。

时间信息在ItemCF上的应用：
- **物品相似度**：用户在相隔很短的时间内喜欢的物品具有更高相似度。
- **在线推荐**：用户近期行为相比用户很久之前的行为，更能体现用户现在的兴趣。

原始ItemCF计算物品间的相似度：

```math
\operatorname { sim } ( i , j ) = \frac { \sum _ { u \in N ( i ) \cap N ( i ) } 1 } { \sqrt { | N ( i ) | | N ( j ) | } }
```
在给用户`$u$`做推荐时，用户`$u$`对物品`$i$`的兴趣`$p(u,i)$`通过如下公式计算：

```math
p ( u , i ) = \sum _ { j \in N ( u ) } \operatorname { sim } ( i , j )
```

加入时间信息后，物品相似度计算做以下改进：

```math
\operatorname { sim } ( i , j ) = \frac { \sum _ { u \in N ( i ) \cap N ( j ) } f \left( \left| t _ { u i } - t _ { u j } \right| \right) } { \sqrt { | N ( i ) | | N ( j ) | } }
```
在分子中引入了和时间有关的衰减项`$f \left( \left| t _ { u i } - t _ { i t } \right| \right)$`。其中`$t _ { u i }$`是用户`$u$`对物品`$i$`产生行为的时间。`$f$`函数的含义是，用户对物品`$i$`和物品`$j$`产生行为的时间越远，则`$f \left( \left| t _ { u i } - t _ { u j } \right| \right)$` 越小。衰减函数有很多，例如：

```math
f \left( \left| t _ { u i } - t _ { u j } \right| \right) = \frac { 1 } { 1 + \alpha \left| t _ { u i } - t _ { u j } \right| }
```

时间信息除了对相似度表的影响，也对对预测公式有影响。用户现在的行为和用户最近的行为关系更大：


```math
p ( u , i ) = \sum _ { j \in N ( u ) \cap S ( i , K ) } \operatorname { sim } ( i , j ) \frac { 1 } { 1 + \beta \left| t _ { 0 } - t _ { u j } \right| }
```

`$t_0$`是当前时间。`$t_{uj}$`越靠近`$t_0$`，和物品`$j$`相似的物品就会在用户`$u$`的推荐列表中获得越高的排名。`$\beta$`是时间衰减参数。

##### 时间上下文相关的UserCF算法

原始的UserCF算法：
1. 找到和目标用户兴趣相似的用户集合
2. 找到这个集合中的用户喜欢的，且目标用户没有行为记录的物品推荐给目标用户

利用时间信息改进UserCF算法：

1. **用户兴趣相似度**：如果两个用户**同时**喜欢相同的物品，那么这两个用户应该有更大的兴趣相似度
2. **相似兴趣用户的最近行为**：给用户推荐和他兴趣相似的用户**最近**喜欢的物品。

原始UserCF算法计算用户`$u$`和用户`$v$`的兴趣相似度：

```math
w _ { u v } = \frac { | N ( u ) \cap N ( v ) | } { \sqrt { | N ( u ) | \cup | N ( v ) | } }
```
在得到用户相似度后，UserCF通过如下公式预测用户对物品的兴趣：

```math
p ( u , i ) = \sum _ { v \in S ( u , K ) } w _ { u v } r _ { v i }
```
`$S(u,K)$`包含了和用户`$u$`兴趣最接近的`$K$`个用户。

加入时间信息后，用户相似度计算做以下改进：

```math
w _ { t w } = \frac { \sum _ { i \in N ( u ) N ( v ) } \frac { 1 } { 1 + \alpha \left| t _ { u i } - t _ { v i } \right| } } { \sqrt { | N ( u ) | \cup | N ( v ) | } }
```

上式对用户`$u$`和用户`$v$`共同喜欢的物品`$i$`增加了一个时间衰减因子。用户`$u$`和用户`$v$`对物品`$i$`产生行为的时间越远，那么这两个用户的兴趣相似度就会越小。

考虑和用户`$u$`兴趣相似用户的**最近**兴趣，预测公式做如下改进：

```math
p ( u , i ) = \sum _ { v \in S ( u , K ) } w _ { u v } r _ { v i } \frac { 1 } { 1 + \alpha \left( t _ { 0 } - t _ { v i } \right) }
```

##### 时间段图模型

时间段图模型`$G \left( U , S _ { U } , I , S _ { I } , E , w , \sigma \right)$`是一个二分图。

`$U$`：用户节点集合

`$S_U$`：用户时间段节点集合

`$I$`：物品节点集合

`$S_I$`：物品时间段节点集合

`$E$`：边集合

`$\sigma(e)$`：定义了顶点的权重

![image](https://github.com/xvlvzhu/reading-notes/blob/master/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5/figure/7.graph_context.png?raw=true)

定义完图的结构后，最简单的想法是可以利用前面提到的PersonalRank算法给用户进行个性化推荐。

### 5.2 地点上下文信息

除了时间，地点作为一种重要的空间特征，也是一种重要的上下文信息。很多基于位置的服务（**LBS**）软件都提供了推荐附近餐馆和商店的功能。

地点相关数据集有三类：

1. （用户，用户位置，物品，评分），每一条记录代表了某一个地点的用户对物品的评分。
2. （用户，物品，物品位置，评分），每一条记录代表了用户对某个地方的物品的评分。
3. （用户，用户位置，物品，物品位置，评分），每一条记录代表了某个位置的用户对某个位置的物品的评分。

用户兴趣和地点相关的两种特征：
1. 兴趣本地化。不同地方的用户兴趣存在着很大的差别。
2. 活动本地化。一个用户往往在附近的地区活动。

#### 5.2.1 基于位置的推荐算法

对于第一类数据集：

![image](https://github.com/xvlvzhu/reading-notes/blob/master/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5/figure/8.LBS_user_local.png?raw=true)

有一个来自中国江苏南京的用户：

1. 首先根据所有用户的行为利用某种推荐算法（假设是ItemCF）给他生成推荐列表
2. 然后利用中国用户的行为给他生成第二个推荐列表，以此类推，用中国江苏的用户行为给该用户生成第三个推荐列表，并利用中国江苏南京的用户行为给该用户生成第四个推荐列表
3. 按照一定的权重将这4个推荐列表线性相加，从而得到给该用户的最终推荐列表。

对于第二类数据集：

利用ItemCF算法计算用户`$u$`对物品`$i$`的兴趣`$P(u,i)$`，但最终物品`$i$`在用户`$u$`的推荐列表中的权重定义为：

```math
\operatorname { Rec } \operatorname { Score } ( u , i ) = P ( u , i ) - \text { TravelPenalty } ( u , i )
```
`$\text { TravelPenalty } ( u , i )$`表示了物品i的位置对用户u的代价。

---
## 6. 利用社交网络数据

严选无社交数据，此节略过。

---
## 7. 推荐系统实例

### 7.1 推荐系统和其他系统的交互

推荐系统除了推荐系统本身，主要还依赖于两个条件——界面展示和用户行为数据。

![image](https://github.com/xvlvzhu/reading-notes/blob/master/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5/figure/9.RS_relation.png?raw=true)

### 7.2 数据收集和存储
电商中的数据类型如下：

行为 |用户类型 |规模| 实时存取
---|---|---|---
浏览网页 |注册/匿名| 大| ×
将商品加入购物车| 注册 |中| √
购买商品| 注册| 中 |√
收藏商品| 注册| 中 |√
评论商品| 注册| 小 |√
给商品评分| 注册| 小| √
搜索商品| 注册/匿名| 大 |×
点击搜索结果| 注册/匿名 |大 |×
分享商品| 注册 |小 |√

按照数据的规模和是否需要实时存取，不同的行为数据将被存储在不同的媒介中：

- 需要实时存取的数据存储在数据库和缓存中。
- 大规模的非实时地存取数据存储在分布式文件系统（如HDFS）中。

### 7.3 推荐系统架构

如果要在一个系统中把各种特征和任务都统筹考虑，那么系统将会非常复杂，而且很难通过配置文件方便地配置不同特征和任务的权重。

因此，推荐系统需要由**多个推荐引擎**组成，每个推荐引擎负责一类特征和一种任务，而推荐系统的任务只是将推荐引擎的结果按照一定权重或者优先级合并、排序然后返回.

![image](https://github.com/xvlvzhu/reading-notes/blob/master/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5/figure/10.RS_constructure.png?raw=true)

### 7.3 推荐引擎架构

推荐引擎架构主要包括3部分。
1. **用户特征生成模块**：负责从数据库或者缓存中拿到用户行为数据，通过分析不同行为，生成当前用户的特征向量。该模块的输出是用户特征向量。
2. **初始推荐列表生成模块**：负责将用户的特征向量通过特征-物品相关矩阵转化为初始推荐物品列表。
3. **后处理模块**：负责对初始的推荐列表进行过滤、排名等处理，从而生成最终的推荐结果。

![image](https://github.com/xvlvzhu/reading-notes/blob/master/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5/figure/11.RS_engine.png?raw=true)

#### 7.3.1 用户特征向量生成

用户的特征包含两种：
1. 用户的统计学特征
2. 用户的行为特征

在利用用户行为计算特征向量是需要考虑：

1. 用户行为的种类
2. 用户行为产生的时间
3. 用户行为的次数
4. 物品的热门程度

#### 7.3.2 特征-物品相关推荐

对于每个特征，在相关表中存储和它最相关的N个物品的ID

src_id |dst_id| weight
---|---|---
特征ID|物品ID|权重

#### 7.3.3 过滤模块

一般来说，过滤模块会过滤掉一下物品。

- 用户已经产生过行为的物品
- 候选物品意外的物品
- 某些质量很差的物品

#### 7.3.4 排名模块

对经过过滤后的推荐结果进行排名，可以更好地提升用户满意度。

1. **新颖性排名**

新颖性排名模块的目的是给用户尽量推荐他们不知道的、长尾中的物品。

其中一种做法是对热门物品进行**降权**：


```math
p _ { u i } = \frac { p _ { u i } } { \log ( 1 + \alpha \cdot \text { popularity } ( i ) ) }
```

基于物品的推荐算法：

```math
p _ { u i } = \sum _ { j \in N ( u ) \cap S ( i , K ) } w _ { j i } r _ { u j }
```
`$r _ { u j }$`在通过用户行为生成用户特征向量时计算，`$w_{ij}$`是离线计算的
物品相似度。

可以分别降低热门物品在`$r _ { u j }$`和`$w_{ij}$`中的权重。

```math
r _ { u j } = \frac { r _ { u j } } { \log ( 1 + \alpha \cdot \text { popularity } ( j ) ) }
```
```math
w _ { j i } = \frac { w _ { j i } } { \log ( 1 + \alpha \cdot \text { popularity } ( i ) ) } ( \text { popularity } ( i ) > \text { popularity } ( j ) )
```

2. **多样性**

增加多样性可以让推荐结果覆盖尽可能多的用户兴趣。

有几种提高多样性的方法：

- 将推荐结果按照某种物品的内容属性分成几类，然后在每个类中都选择该类中排名最高的物品组合成最终的推荐列表。
- 控制不同推荐结果的推荐理由出现的次数。

3. **时间多样性**

保证用户每天看到不同的推荐结果。

- 如果用户有实时行为发生，行为提取和分析模块实时拿到行为数据并转化为新的特征，经过特征-物品相关模块转换成和新特征最相关的物品。
- 用户没有新的行为时，也要保证推荐结果每天都有变化：
    - 记录用户每次登陆推荐系统看到的推荐结果。
    - 将这些结果发回日志系统。这种数据不需要实时存储，只要能保证小于一天的延时就足够了。
    - 在用户登录时拿到用户昨天及之前看过的推荐结果列表，从当前推荐结果中将用户已经看到的推荐结果降权。

4. **用户反馈**

用户反馈模块主要通过分析用户之前和推荐结果的交互日志，预测用户会对什么样的推荐结果比较感兴趣。

一般使用点击模型（click model）预测用户是否会点击推荐结果。可以使用以下特征预测用户`$u$`会不会点击物品`$i$`：

- 用户u相关的特征，比如年龄、性别、活跃程度、之前有没有点击行为；
- 物品i相关的特征，比如流行度，平均分，内容属性；
- 物品i在推荐列表中的位置。用户的点击和用户界面的设计有很高的相关性，因此物品i在推荐列表中的位置对预测用户是否点击很重要；
- 用户之前是否点击过和推荐物品i具有同样推荐解释的其他推荐结果；
- 用户之前是否点击过和推荐物品i来自同样推荐引擎的其他推荐结果。

---
## 8. 评分预测问题

评分预测问题都是推荐系统研究的核心。每一条评分记录是一个三元组`$(u, i, r)$`，表示用户`$u$`给物品`$i$`赋予了评分`$r$`。

### 8.1 离线实验方法

```math
\mathrm { RMSE } = \frac { \sqrt { \sum _ { ( u , i ) \in T } \left( r _ { u i } - \hat { r } _ { u i } \right) ^ { 2 } } } { | \text { Test } | }
```

用户`$u$`对物品`$i$`的真实评分是`$r_{ui}$`，推荐算法预测的用户对物品`$i$`的评分为`$\hat { r } _ { u i }$`。

### 8.2 评分预测方法

#### 8.2.1. 平均值

1. 全局平均值
    
```math
\hat { r } _ { u i } = \frac { \sum _ { ( u , i ) \in \operatorname { Train } } r _ { u i } } { \sum _ { ( u , i ) \in \operatorname { Train } } 1 }
```

2. 用户评分平均值


```math
\hat { r } _ { u i }= \frac { \sum _ { i \in N ( u ) } r _ { u i } } { \sum _ { i \in N ( u ) } 1 }
```

3. 物品评分平均值

```math
\hat { r } _ { u i } = \frac { \sum _ { u \in N ( i ) } r _ { u i } } { \sum _ { u \in N ( i ) } 1 }
```

4. 用户分类对物品分类的平均值

```math
\hat { r } _ { u i } = \frac { \sum _ { ( v , j ) \in \operatorname { Train } , \phi ( u ) = \phi ( v ) , \varphi ( i ) = \varphi ( j ) } r _ { v j } } { \sum _ { ( v , j ) \in \operatorname { Train } , \phi ( u ) = \phi ( v ) , \varphi ( i ) = \varphi ( j ) } 1 }
```

#### 8.2.2 基于邻域的方法

基于**用户**的邻域算法和基于**物品**的邻域算法都可以应用到评分预测中

##### 基于用户的邻域算法

```math
\hat { r } _ { u i } = \overline { r } _ { u } + \frac { \sum _ { v \in S ( u , K ) \cap N ( i ) } w _ { u v } \left( r _ { v i } - \overline { r } _ { v } \right) } { \sum _ { v \in S ( u , K ) \cap N ( i ) } \left| w _ { u v } \right| }
```
`$S(u, K)$`是和用户`$u$`兴趣最相似的`$K$`个用户的集合，`$N(i)$`是对物品`$i$`评过分的用户集合，`$r_{vi}$`是用户`$v$`对物品i的评分， `$\overline { r _ { v } }$` 是用户`$v$`对他评过分的所有物品评分的平均值

##### 基于物品的邻域算法

```math
\hat { r } _ { u i } = \overline { r } _ { i } + \frac { \sum _ { j \in S ( u , K ) \cap N ( u ) } w _ { i j } \left( r _ { u j } - \overline { r } _ { i } \right) } { \sum _ { j \in S ( i , K ) \cap N ( u ) } \left| w _ { i j } \right| }
```
`$S(i, K)$`是和`$i$`最相似的物品集合，`$N(u)$`是用户`$u$`评过分的物品集合， `$w_{ij}$`是物品之间的相似度，`$\overline { r _ { i } }$` 是物品`$i$`的平均分

#### 8.2.3 隐语义模型与矩阵分解模型

隐含类别模型（Latent Class Model）、隐语义模型（Latent Factor Model）、pLSA、LDA、Topic Model、Matrix Factorization、Factorized Model

在推荐系统领域，隐语义模型和矩阵分解模型是一样的，就是如何通过降维的方法将评分矩阵补全。

1. 传统SVD分解

```math
R ^ { \prime } = U ^ { T } S V
```

2. Latent Factor Model（**LFM**）

将评分矩阵`$R$`分解为两个低维矩阵相乘。

```math
\hat { R } = P ^ { T } Q
```

以RMSE作为评测指标，找到合适的`$P$`、`$Q$`最小化训练集的预测误差，定义损失函数为：

```math
C ( p , q ) = \sum _ { ( u , i ) \in \text { Train } } \left( r _ { u i } - \hat { r } _ { u i } \right) ^ { 2 } = \sum _ { ( u , i ) \in \operatorname { Train } } \left( r _ { u i } - \sum _ { f = 1 } ^ { F } p _ { u f } q _ { i f } \right) ^ { 2 }
```
需要加入防止过拟合的正则项：

```math
C ( p , q ) = \sum _ { ( u , i ) \in \operatorname { Train } } \left( r _ { u i } - \sum _ { f = 1 } ^ { F } p _ { u f } q _ { i f } \right) ^ { 2 } + \lambda \left( \left\| p _ { u } \right\| ^ { 2 } + \left\| q _ { i } \right\| ^ { 2 } \right)
```
利用随机梯度下降法进行求解。

3. 加入偏置项后的LFM——**BasicSVD**

```math
\hat { r } _ { u i } = \mu + b _ { u } + b _ { i } + p _ { u } ^ { T } \cdot q _ { i }
```

加入了三项偏置项：

`$\mu$` 训练集中所有记录的评分的全局平均数。

`$b_u$` 用户偏置（userbias）项。表示用户的评分习惯中和物品没有关系的那种
因素。比如有些用户就是比较苛刻，对什么东西要求都很高，那么他的评分就会偏低，

`$b_i$`物品偏置（item bias）项。这一项表示了物品接受的评分中和用户没有什么关系的
因素。比如有些物品本身质量就很高，因此获得的评分相对都比较高，而有些物品本身
质量很差，因此获得的评分相对都会比较低。

4. 考虑邻域影响的LFM——**SVD++**


```math
\hat { r } _ { u i } = \mu + b _ { u } + b _ { i } + q _ { i } ^ { T } \cdot \left( p _ { u } + \frac { 1 } { \sqrt { | N ( u ) | } } x _ { i } ^ { T } \sum _ { j \in N ( u ) } y _ { j } \right)
```