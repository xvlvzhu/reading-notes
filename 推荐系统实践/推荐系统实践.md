## 1. 推荐系统

1. 推荐系统简介
2. 与搜索引擎的区别
3. 推荐系统评测

### 1.1 推荐系统简介
随着互联网发展，信息匮乏走向信息过载（information overload）

两个挑战：
1. 信息消费者，如何找到感兴趣的信息
2. 信息生产者，如何使生产的信息脱颖而出

推荐系统是解决两个问题的重要工具。推荐系统的任务是**联系用户和信息**。
1. 帮助用户找到有价值的信息
2. 信息展现在对它感兴趣的用户面前

### 1.2 与搜索引擎的区别
面对信息过载，代表性的解决方案是分类目录和搜索引擎（雅虎、谷歌）。

##### 从用户角度出发：

搜索引擎需要**用户主动提供准确的关键词**。

推荐系统**不需要用户提供显示需求**，而是分析用户的历史行为，主动给用户推荐满足兴趣和需求的信息。

一定程度上，推荐和搜索是两个互补的工具。
- 搜索引擎满足用户**有明确目的**的主动查找需求。
- 推荐系统在用户**没有明确目的**时帮助他们发现感兴趣的内容。

##### 从物品角度出发：

推荐系统可以更好的**发掘长尾**（long tail）。

推荐系统通过挖掘用户行为，从长尾商品中准确的推荐给用户，提高长尾销售额。

### 1.3 推荐系统评测

推荐系统组成：用户、物品提供者和推荐系统网站。

##### 推荐系统实验方法：
1. **离线实验**：只利用日志系统数据训练测试。
2. **用户调查**：通过用户问卷行为和答案了解系统的性能。
3. **在线实验**：线上AB测试。如下图所示:

![image](https://raw.githubusercontent.com/xvlvzhu/reading-notes/master/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5/figure/1.ABtest.png)

##### 评测指标：
1. **用户满意度**
2. **预测准确度**

```math
\operatorname { RMSE } = \frac { \sqrt { \sum _ { u , k \in T } \left( r _ { u i } - \hat { r } _ { u i } \right) ^ { 2 } } } { | T | }
```


```math
\mathrm { MAE } = \frac { \sum _ { u , i \in T } \left| r _ { u i } - \hat { r } _ { u i } \right| } { | T | }
```

`$u$`：用户，`$i$`：物品，`$r_{ui}$`：用户u对物品i的实际评分，`$\hat{r}_{ui}$`:推荐算法给出的预测评分

```math
\operatorname { Recall } = \frac { \sum _ { u \in U } | R ( u ) \cap T ( u ) | } { \sum _ { u \in U } | T ( u ) | }
```


```math
\operatorname { Precision }= \frac { \sum _ { u \in U } | R ( u ) \cap T ( u ) | } { \sum _ { i \in U } | R ( u ) | }
```

`$R(u)$`：根据用户在训练集上的行为给用户作出的推荐列表

`$T(u)$`：是用户在测试集上的行为列表

3. **覆盖率**：描述推荐系统对物品长尾的发掘能力。

```math
\operatorname { Coverage }= \frac { \left| \bigcup _ { u \in \mathrm { U } } R ( u ) \right| } { | I | }
```
系统的用户集合为`$U$`，推荐系统给每个用户推荐一个长度为N的物品列表`$R(u)$`。

4. **多样性**：推荐列表中物品两两之间的不相似性。

```math
\operatorname { Diversity }= 1 - \frac { \sum _ { i , j \in R ( u ) , i \neq j } s ( i , j ) } { \frac { 1 } { 2 } | R ( u ) | ( | R ( u ) | - 1 ) }
```

`$s(i, j)$`：物品`$i$`和`$j$`之间的相似度；

整个系统的推荐多样性：

```math
\operatorname { Diversity }= \frac { 1 } { | U | _ { u \in U } } \operatorname { Diversity } ( R ( u ) )
```

5. **新颖性**：一般热度越低，新颖性越高
6. **惊喜度**：推荐结果和用户历史兴趣不相似，但却让用户满意，惊喜度就较高
7. **信任度**：用户对推荐系统的信任。需要增加推荐透明度（提供推荐解释）。社交好友的推荐（评论信任）。
8. **实时性**：用户行为后推荐的及时性，新物品的冷启动能力。 
9. **健壮性**：推荐系统抗击作弊的能力。提高健壮性的方式：1.尽量使用代价比较高的用户行为（如购买行为）。2.进行数据清理。
10. **商业目标**
11. **总结**：优化离线指标，在给定覆盖率，多样性、新颖性等限制条件下，尽量优化预测准确度。离线实验的优化目标是：

```
max 预测准确率
st. 覆盖率>A
    多样性>B
    新颖性>C
```
---

## 2. 利用用户行为数据

用户行为数据蕴含着很多不是那么显而易见的规律（如啤酒和尿布），个性化推荐算法的任务是通过计算机发现这些规律，为产品的设计提供指导。

### 2.1 用户行为数据
用户行为数据的一般存在形式是**日志**。

- 展示日志：用户查询后页面中展示的结果
- 点击日志：用户的点击行为
- 会话日志：展示日志和点击日志的归并

会话日志通常存储于分布式数据仓库中。
- 支持离线分析的**Hadoop Hive**
- 支持在线分析的**Google Dremel**

用户行为分为两种：
- 显示反馈行为（explicit feedback）：用户明确表示对物品喜好的行为（如评分）。
- 隐式反馈行为（implicit feedback）：不能明确反应用户喜好的行为（如页面浏览）。

用户行为可以统一表示为下表：

字段 | 意义
---|---
user id| 产生行为的用户的唯一标识
item id| 产生行为的对象的唯一标识
behavior type| 行为的种类（比如是购买还是浏览）
context| 产生行为的上下文，包括时间和地点等
behavior weight| 行为的权重（如浏览时长）
behavior content| 行为的内容（如评论文本）

考虑到隐式/显示，有无上下文，数据可以分为以下几类：


用户反馈| 上下文信息| 包含内容|示例
---|---|---|---
隐性 | 无 | 用户ID和物品ID| [Book-Crossing](http://www.informatik.uni-freiburg.de/~cziegler/BX/)
显性 | 无 | 用户ID、物品ID，用户对物品评分|
隐性 | 有 | 用户ID、物品ID和行为时间戳|[Last.fm](http://www.dtic.upf.edu/~ocelma/MusicRecommendationDataset/lastfm-1K.html)
显性 | 无 | 用户ID、物品ID，用户对物品评分、行为时间戳|[Netflix.Price](https://netflixprize.com/)

### 2.2 用户行为分析

- 物品流行度和用户活跃度一般呈长尾分布。
- 用户越活跃，更倾向浏览冷门物品。

基于用户行为数据设计的推荐算法一般称为**协同过滤算法**。主流方法有一下几种：

- 基于近邻的方法（neighborhood-based）
    - 基于用户的协同过滤算法：给用户推荐与他兴趣相似的其他用户喜欢的物品
    - 基于物品的协同过滤算法：给用户推荐与他之前喜欢的物品相似的物品
- 隐语义模型（latent factor model）
- 基于图的随机游走算法（random walk on graph）

### 2.3 基于邻域的算法

#### 2.3.1 基于用户的协同过滤算法
1. 找到和目标用户兴趣相似的用户集合
2. 找到这个集合中的用户喜欢的，且目标用户没有行为记录的物品推荐给目标用户

给定用户`$u$`和用户`$v$`，`$N(u)$`表示用户`$u$`曾经有过正反馈的物品集合，`$N(v)$`为用户`$v$`曾经有过正反馈的物品集合。利用Jaccard公式计算兴趣相似度：

```math
w _ { u v } = \frac { | N ( u ) \cap N ( v ) | } { | N ( u ) \cup N ( v ) | }
```
或通过余弦相似度计算：

```math
w _ { u v } = \frac { | N ( u ) \cap N ( v ) | } { \sqrt { | N ( u ) | | N ( v ) | } }
```

用户相似度计算改进（User-IIF算法）：

对于热度较大的物品`$i$`进行权重惩罚，热度越大的商品在相似度计算中占得的权重越低：
```math
w _ { u v } = \frac { \sum _ { i \in N ( u ) \cap N ( v ) } \frac { 1 } { \log 1 + | N ( i ) | } } { \sqrt { | N ( u ) | | N ( v ) | } }
```
##### UserCF代码：

```python
# 计算用户相似度矩阵
def UserSimilarity(train, mode='UserCF'):
    # build inverse table for item_users
    item_users = dict()
    for u, items in train.items():
        for i in items.keys():
            if i not in item_users:
                item_users[i] = set()
            item_users[i].add(u)
            
    #calculate co-rated items between users
    C = dict()
    N = dict()
    for i, users in item_users.items():
        for u in users:
            N[u] += 1
            for v in users:
                if u == v:
                    continue
                if mode=='UserCF':
                    C[u][v] += 1 # UserCF算法
                else:
                    C[u][v] += 1 / math.log(1 + len(users)) # User-IIF算法
                
    #calculate finial similarity matrix W
    W = dict()
    for u, related_users in C.items():
        for v, cuv in related_users.items():
            W[u][v] = cuv / math.sqrt(N[u] * N[v])
    return W

# 根据用户相似度矩阵进行推荐
def Recommend(user, train, W):
    rank = dict()
    interacted_items = train[user]
    for v, wuv in sorted(W[u].items, key=itemgetter(1), \
        reverse=True)[0:K]:
        for i, rvi in train[v].items:
            if i in interacted_items:
                #we should filter items user interacted before
                continue
            rank[i] += wuv * rvi
    return rank
```

#### 2.3.2 基于物品的协同过滤算法
1. 计算物品之间的相似度。
2. 根据物品的相似度和用户的历史行为给用户生成推荐列表。

物品相似度计算公式：

```math
w _ { i j } = \frac { | N ( i ) \cap N ( j ) | } { \sqrt { | N ( i ) || N ( j ) | } }
```

`$|N(i)|$`是喜欢物品`$i$`的用户数，`$|N(j)|$`是喜欢物品`$j$`的用户数，`$|N(i) \cap N(j)|$`是同时喜欢物品`$i$`和物品`$j$`的用户数.

物品相似度的修正公式IUF（Inverse User Frequence）：活跃用户对物品的相似度的贡献应小于不活跃的用户。

```math
w _ { i j } = \frac { \sum _ { u \in N ( i ) N ( j ) } \frac { 1 } { \log 1 + | N ( u ) | } } { \sqrt { | N ( i ) | | N ( j ) | } }
```

`$|N(u)|$`为用户`$u$`喜欢物品的数量。


```python
# 计算物品相似度矩阵
def ItemSimilarity(train, mode='ItemCF'):
    #calculate co-rated users between items
    C = dict()
    N = dict()
    for u, items in train.items():
        for i in users:
            N[i] += 1
            for j in users:
                if i == j:
                    continue
                if mode=='ItemCF':
                    C[i][j] += 1 # ItemCF算法
                else:
                    C[i][j] += 1 / math.log(1 + len(items) * 1.0) # ItemCF-IUF
            
    #calculate finial similarity matrix W
    W = dict()
    for i,related_items in C.items():
        for j, cij in related_items.items():
            W[u][v] = cij / math.sqrt(N[i] * N[j])
    return W
    
def Recommendation(train, user_id, W, K):
    rank = dict()
    ru = train[user_id]
    for i,pi in ru.items():
        for j, wj in sorted(W[i].items(), \
                            key=itemgetter(1), reverse=True)[0:K]:
            if j in ru:
                continue
            rank[j].weight += pi * wj \\ # 计算用户对物品j的兴趣度
            rank[j].reason[i] = pi * wj
    return rank
```

物品相似度归一化：ItemCF相似度矩阵按最大值归一化，可以提高推荐的准确率。
```math
w _ { i j } ^ { \prime } = \frac { w _ { i j } } { \mathop {\max }\limits_j w _ { i j } }

```

#### 2.3.3 UserCF和ItemCF对比



-|UserCF | ItemCF
---|---|---
性能|适用于用户较少的场合，如果用户很多，计算用户相似度矩阵代价很大 | 适用于物品数明显小于用户数的场合，如果物品很多（网页），计算物品相似度矩阵代价很大
领域| 时效性较强，用户个性化兴趣不太明显的领域 | 长尾物品丰富，用户个性化需求强烈的领域
实时性|用户有新行为，不一定造成推荐结果的立即变化|用户有新行为，一定会导致推荐结果的实时变化
冷启动| 在新用户对很少的物品产生行为后，不能立即对他进行个性化推荐，因为用户相似度表是每隔一段时间离线计算的。新物品上线后一段时间，一旦有用户对物品产生行为，就可以将新物品推荐给和对它产生行为的用户兴趣相似的其他用户| 新用户只要对一个物品产生行为，就可以给他推荐和该物品相关的其他物品。但没有办法在不离线更新物品相似度表的情况下将新物品推荐给用户
推荐理由| 很难提供令用户信服的推荐解释|利用用户的历史行为给用户做推荐解释，可以令用户比较信服

### 2.4 隐语义模型

隐语义模型（latent factor model）通过**隐含特征**（latent factor）联系用户的兴趣和物品。

隐语义模型包括pLSA、LDA、隐含类别模型、隐含主题模型、矩阵分解（matrix factorization）。

#### 2.4.1 LFM模型

LFM通过如下公式计算用户u对物品i的兴趣：


```math
\operatorname { Preference }( u , i ) = r _ { u i } = p _ { u } ^ { T } q _ { i } = \sum _ { f = 1 } ^ { F } p _ { u , k } q _ { i , k }
```

`$p _ { u , k }$`和`$q _ { i , k }$`是模型的参数，其中`$p _ { u , k }$`度量了用户`$u$`的兴趣和第`$k$`个隐类的关系，而`$q _ { i , k }$`度量了第`$k$`个隐类和物品`$i$`之间的关系。

计算`$p _ { u , k }$`和`$q _ { i , k }$`需要一个训练集，包括用户`$u$`喜欢的物品和不感兴趣的物品。但是在隐式反馈数据集中没有负样本（用户不感兴趣的物品）。

LFM的应用需要解决**负样本生成**问题。一种基本方法是：对于一个用户，从他没有过行为的物品中采样出一些物品作为负样本，采样时，保证每个用户的正负样本数目相当。


实验表明负样本采样应包含以下原则：
- 对每个用户，要保证正负样本的平衡（数目相似）。
- 对每个用户采样负样本时，要选取那些很热门，而用户却没有行为的物品。


```python
# 负样本采样过程
def RandomSelectNegativeSample(self, items):
    ret = dict()
    for i in items.keys():
        ret[i] = 1
    n = 0
    for i in range(0, len(items) * 3):
        item = items_pool[random.randint(0, len(items_pool) - 1)] # items_pool候选物品列表
        if item in ret:
            continue
        ret[item] = 0
        n + = 1
        if n > len(items):
            break
    return ret
```

经过负采样得到用户-物品样本`$K={(u,i)}$`，其中如果`$(u, i)$`是正样本，则有`$r_{ui}=1$`，否则`$r_{ui}=0$`。

然后优化一下损失寻找合适的`$p$`和`$q$`：
```math
C = \sum _ { ( u , i ) \in K } \left( r _ { u i } - \hat { r } _ { u i } \right) ^ { 2 } = \sum _ { ( u , i ) \in K } \left( r _ { u i } - \sum _ { k = 1 } ^ { K } p _ { u , k } q _ { i , k } \right) ^ { 2 } + \lambda \left\| p _ { u } \right\| ^ { 2 } + \lambda \left\| q _ { i } \right\| ^ { 2 }
```

`$\lambda \left\| p _ { u } \right\| ^ { 2 } + \lambda \left\| q _ { i } \right\| ^ { 2 }$`为防止过拟合的正则项，`$\lambda$`为超参数，通过随机梯度下降算法，优化参数。

对参数`$p$`和`$q$`**求偏导数**:


```math
\begin{array} { l } { \frac { \partial C } { \partial p _ { u k } } = - 2 q _ { i k } + 2 \lambda p _ { u k } } \\ \\ { \frac { \partial C } { \partial q _ { k k } } = - 2 p _ { u k } + 2 \lambda q _ { l k } } \end{array}
```

梯度下降法更新参数：

```math
\begin{aligned} p _ { u k } & = p _ { u k } + \alpha \left( q _ { i k } - \lambda p _ { u k } \right) \\ q _ { i k } & = q _ { i k } + \alpha \left( p _ { u k } - \lambda q _ { i k } \right) \end{aligned}
```


```python
# LMF 模型训练
def LatentFactorModel(user_items, F, N, alpha, lambda):
    [P, Q] = InitModel(user_items, F)
    for step in range(0,N):
        for user, items in user_items.items():
            samples = RandSelectNegativeSamples(items) # 采样负样本
            for item, rui in samples.items():
                eui = rui - Predict(user, item) # 计算误差
                for f in range(0, F):
                    P[user][f] += alpha * (eui * Q[item][f] - \
                        lambda * P[user][f]) # 更新用户矩阵
                    Q[item][f] += alpha * (eui * P[user][f] - \
                        lambda * Q[item][f]) # 更新物品矩阵
        alpha *= 0.9

def Recommend(user, P, Q):
    rank = dict()
    for f, puf in P[user].items():
        for i, qfi in Q[f].items():
            if i not in rank:
                rank[i] += puf * qfi
    return rank
```

#### 2.4.2 LMF与基于邻域的方法对比


-|LMF | 基于邻域
---|---|---
理论|最优化方法 | 统计方法
空间复杂度|`$O(F\times (M+ N))$` | `$O(M\times M)$`或`$O(N\times N)$`
时间复杂度|`$O(K\times F\times S)$`|`$O(N\times (K/N)^2)$`或`$O(M\times (K/M)^2)$`
在线实时推荐| 不能 |可以
推荐解释|不能|ItemCF可以

`$M$`个用户，`$N$`个物品，`$K$`条用户对物品的行为记录

### 2.5 基于图的模型

将用户行为数据表示为**图**的形式。

用户行为数据是由二元组组成，每个二元组(u, i)表示用户u对物品i产生过行为。

![image](https://github.com/xvlvzhu/reading-notes/blob/master/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5/figure/2.graph_model.png?raw=true)

`$G(V,E)$`表示用户物品二分图，`$V = V _ { U } \cup V _ { I }$` 表示用户和物品的顶点集合，边`$e \left( v _ { u } , v _ { i } \right)$`表示用户u对物品i产生过行为。

给用户u推荐物品的任务转化为：度量`$v_u$`和与`$v_u$`没有直接相连的物品节点的相关性。

#### 2.5.1 随机游走算法

从用户`$u$`对应的节点`$v_u$`开始在用户物品二分图上进行随机游走。游走到任何一个节点时，首先按照概率`$\alpha$`决定是继续游走，还是停止这次游走并从`$v_u$`节点开始重新游走。如果决定继续游走，那么就从当前节点指向的节点中按照均匀分布随机选择一个节点作为游走下次经过的节点。经过很多次随机游走后，每个物品节点被访问到的概率会收敛到一个数。最终的推荐列表中物品的权重就是物品节点的访问概率。

```math
{\rm{PR}}(v)\left\{ \begin{array}{l}
\alpha \sum\limits_{{v^\prime } \in {\rm{in}}(v)} {\frac{{{\rm{PR}}\left( {{v^\prime }} \right)}}{{\left| { out \left( {{v^\prime }} \right)} \right|}}} \quad \left( {v \ne {v_u}} \right)\\
(1 - {\rm{ }}\alpha ) + \alpha \sum\limits_{{v^\prime } \in  in (v)} {\frac{{ PR \left( {{v^\prime }} \right)}}{{\left| { out \left( {{v^\prime }} \right)} \right|}}} \quad \left( {v = {v_u}} \right)
\end{array} \right.
```

---

## 3. 推荐系统冷启动问题

### 3.1 冷启动问题简介
在没有大量用户数据的情况下设计推荐系统，即为冷启动问题。

冷启动问题（cold start）分为三类。
- 用户冷启动：新用户的推荐问题
- 物品冷启动：把新物品推荐给感兴趣的用户
- 系统冷启动：在新开发的网站上设计个性化推荐系统

一般来说有如下解决方案：
1. 提供非个性化的推荐，例如排行榜。
2. 利用用户注册时提供的年龄、性别等数据做粗粒度的个性化。
3. 利用用户的社交网络账号登录（需要用户授权），导入用户在社交网站上的好友信息，然后给用户推荐其好友喜欢的物品。
4. 要求用户在登录时对一些物品进行反馈，收集用户对这些物品的兴趣信息，然后给用户
推荐那些和这些物品相似的物品。
5. 对于新加入的物品，可以利用内容信息，将它们推荐给喜欢过和它们相似的物品的用户。
6. 在系统冷启动时，可以引入专家的知识，通过一定的高效方式迅速建立起物品的相关度表。

### 3.2 利用用户注册信息

用户注册信息分三类：

1. 人口统计学信息：包括用户的年龄、性别、职业、民族、学历和居住地。
2. 户兴趣的描述：有一些网站会让用户用文字描述他们的兴趣。
3. 从其他网站导入的用户站外行为数据：比如用户通过豆瓣、新浪微博的账号登录，就可以在得到用户同意的情况下获取用户在豆瓣或者新浪微博的一些行为数据和社交网络数据。

基于注册信息的个性化推荐流程基本如下：
1. 获取用户的注册信息；
2. 根据用户的注册信息对用户分类；
3. 给用户推荐他所属分类中用户喜欢的物品。

![image](https://github.com/xvlvzhu/reading-notes/blob/master/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5/figure/3.cold_start.png?raw=true)

基于用户注册信息的推荐算法：计算每种特征的用户喜欢的物品。
```math
p ( f , i ) = | N ( i ) \cap U ( f ) |
```
`$p ( f , i ) $`定义为物品`$i$`在具有`$f$`特征的用户中的热门度。